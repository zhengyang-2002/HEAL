{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab807e2-f1ea-4c47-86dd-623cf202fc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b16c36ab5324ea0ab37b46e847005cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! A Large Language Model (LLM) is a type of artificial intelligence model designed to understand and generate human-like text. These models are typically based on deep learning techniques, particularly transformer architectures, which enable them to process and understand the context of words in a sentence or document.\n",
      "\n",
      "LLMs are trained on vast amounts of textual data from the internet, books, articles, and other sources, allowing them to learn complex patterns and relationships within the language. This training enables LLMs to perform various natural language processing tasks, such as translation, summarization, question answering, text generation, and more.\n",
      "\n",
      "Some notable examples of LLMs include:\n",
      "\n",
      "1. **GPT (Generative Pre-trained Transformer)**: Developed by OpenAI, GPT is known for its ability to generate coherent and contextually relevant text.\n",
      "2. **BERT (Bidirectional Encoder Representations from Transformers)**: Created by Google, BERT is designed to understand the context of words in both directions, making it effective for tasks like sentiment analysis and named entity recognition.\n",
      "3. **T5 (Text-to-Text Transfer Transformer)**: Also developed by Google, T5 is a unified architecture that can be fine-tuned for various text-based tasks, including summarization and translation.\n",
      "\n",
      "LLMs have become increasingly powerful and versatile, offering significant advancements in areas such as conversational AI, content creation, and information retrieval. However, they also raise concerns around ethical use, bias, and potential misuse.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Local path to the model and tokenizer\n",
    "model_path = \"/root/model_weights/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "# Load the model from the local path\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16,  # or \"auto\" if you want to automatically choose the dtype\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load the tokenizer from the local path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "# Apply chat template\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# Prepare model inputs\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate response\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "\n",
    "# Extract generated tokens\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "# Decode the response\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4046605-5f58-4048-854e-2aff598c641a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
